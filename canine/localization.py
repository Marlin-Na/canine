import os
import sys
import warnings
from uuid import uuid4
from collections import namedtuple
from .backends import AbstractSlurmBackend, AbstractTransport
from .utils import get_default_gcp_project

# * `CANINE`: The current canine version
# * `CANINE_BACKEND`: The name of the current backend type
# * `CANINE_ADAPTER`: The name of the current adapter type
# * `CANINE_ROOT`: The path to the staging directory
# * `CANINE_COMMON`: The path to the directory where common files are localized
# * `CANINE_OUTPUT`: The path to the directory where job outputs will be staged during delocalization
# * `CANINE_JOB_VARS`: A colon separated list of the names of all variables generated by job inputs
# * `CANINE_JOB_INPUTS`: The path to the directory where job inputs are localized
# * `CANINE_JOB_ROOT`: The path to the working directory for the job. Equal to CWD at the start of the job. Output files should be written here

# $CANINE_ROOT: staging dir
#   /common: common inputs
#   /outputs: output dir
#       /{jobID}: job specific output
#   /jobs/{jobID}: job staging dir
#       setup.sh: setup script
#       script.sh: main script
#       teardown.sh: teardown script
#       /inputs: job specific input
#       /workspace: job starting cwd and output dir

Localization = namedtuple("Localization", ['type', 'path'])
# types: stream, download, None
# indicates what kind of action needs to be taken during job startup

class Localizer(object):
    """
    Class for handling file localization and delocalization
    Responsible for setting up staging directories and managing inputs and outputs
    NOT responsible for copying results to FireCloud (handled at the adapter layer)
    """

    def __init__(self, backend: AbstractSlurmBackend, localize_gs: bool = True, common: bool = True, staging_dir: path = None):
        """
        Initializes the Localizer using the given transport.
        Localizer assumes that the SLURMBackend is connected and functional during
        the localizer's entire life cycle.
        If staging_dir is not provided, a random directory is chosen
        """
        self.backend = backend
        self.localize_gs = localize_gs
        self.common = common
        self.common_inputs = set()
        self.__sbcast = False
        if staging_dir == 'SBCAST':
            self.__sbcast = True
            staging_dir = None
        self.staging_dir = staging_dir if staging_dir is not None else str(uuid4())
        self.inputs = {} # {jobId: {inputName: (handle type, handle value)}}
        self.requester_pays = {}
        self.env = {
            'CANINE_ROOT': self.staging_dir,
            'CANINE_COMMON': os.path.join(self.staging_dir, 'common'),
            'CANINE_OUTPUT': os.path.join(self.staging_dir, 'outputs'), #outputs/jobid/outputname/...files...
            'CANINE_JOBS': os.path.join(self.staging_dir, 'jobs'),
        }

    def __enter__(self):
        """
        Sets up staging directory for the job
        """
        with self.backend.transport() as transport:
            transport.mkdir(self.env['CANINE_ROOT'])
            transport.mkdir(self.env['CANINE_COMMON'])
            transport.mkdir(self.env['CANINE_OUTPUT'])
            transport.mkdir(self.env['CANINE_JOBS'])

    def __exit__(self, *args):
        """
        Assumes outputs have already been delocalized.
        Removes the staging directory
        """
        self.backend.invoke('rm -rf {}'.format(self.env['CANINE_ROOT']))

    def get_requester_pays(self, path: str) -> bool:
        """
        Returns True if the requested gs:// object or bucket resides in a
        requester pays bucket
        """
        if path.startswith('gs://'):
            path = path[5:]
        bucket = path.split('/')[0]
        if bucket not in self.requester_pays:
            rc, sout, serr = self.backend.invoke('gsutil ls -Lb gs://{}'.format(bucket))
            if rc == 0:
                self.requester_pays[bucket] = len([line for line in sout.readlines() if b'Requester Pays enabled:' in line and b'True' in line]) >= 1
        return bucket in self.requester_pays and self.requester_pays[bucket]

    def localize(self, inputs: typing.Dict[str, typing.Dict[str, str]], overrides: typing.Optional[typing.Dict[str, typing.Optional[str]]] = None):
        """
        Localizes all input files
        Inputs: {jobID: {inputName: inputValue}}
        Overrides: {inputName: handling}
        """
        if overrides is None:
            overrides = {}
        with self.backend.transport() as transport:
            if self.common:
                for varname, values in inputs.items():
                    if len(values) > len(set(values.values())):
                        self.common_inputs |= set(values.values())
                    self.common_inputs |= {path for arg, path in values.items() if arg in overrides and overrides['arg'] == 'common'}
            common_dests = {}
            for path in self.common_inputs:
                if path.startswith('gs://') and self.localize_gs:
                    common_dests[path] = os.path.join(self.env['CANINE_COMMON'], os.path.basename(path))
                    self.backend.invoke("gsutil {} cp {} {}".format(
                        '-u {}'.format(get_default_gcp_project()) if self.get_requester_pays(path) else '',
                        path,
                        common_dests[path]
                    ))
                elif os.path.isfile(path):
                    common_dests[path] = os.path.join(self.env['CANINE_COMMON'], os.path.basename(path))
                    transport.send(
                        path,
                        common_dests[path]
                    )
                else:
                    print("Could not handle common file", path, file=sys.stderr)
            for jobId, data in inputs.items():
                self.inputs[jobId] = {}
                for arg, value in data.items():
                    mode = overrides[arg] if arg in overrides else False
                    if mode is not False:
                        if mode is 'stream':
                            self.inputs[jobId][arg] = Localization('stream', value)
                        elif mode == 'localize':
                            self.inputs[jobId][arg] = Localization(
                                None,
                                self.localize_file(transport, jobId, arg, value)
                            )
                        elif mode == 'delayed':
                            if not value.startswith('gs://'):
                                print("Ignoring 'delayed' override for", arg, "with value", value, "and localizing now", file=sys.stderr)
                                self.inputs[jobId][arg] = Localization(
                                    None,
                                    self.localize_file(transport, jobId, arg, value)
                                )
                            else:
                                self.inputs[jobId][arg] = Localization(
                                    'download',
                                    self.localize_file(transport, jobId, arg, value, True)
                                )
                        elif mode is None:
                            self.inputs[jobId][arg] = Localization(None, value)
                    elif value in common_dests:
                        # common override already handled
                        # No localization needed, already copied
                        self.inputs[jobId][arg] = Localization(None, common_dests[value])
                    else:
                        self.inputs[jobId][arg] = Localization(
                            None,
                            self.localize_file(transport, jobId, arg, value)
                        )

    def localize_file(self, transport: AbstractTransport, jobId: int, name: str, value: str, delayed: bool = False) -> str:
        """
        Localizes an individual file.
        Expects the caller to have initialized the transport and entered its context
        Common and stream handling are taken care of externally. This function only runs
        for files which are set to localize for each job
        If delayed is True, only a path will be produced, but no localization will occur
        """
        filepath = os.path.join(
            self.env['CANINE_JOBS'],
            str(jobId),
            'inputs',
            os.path.basename(value)
        )
        transport.makedirs(os.path.dirname(filepath))
        while transport.exists(filepath):
            root, ext = os.path.splitext(filepath)
            filepath = '{}._alt{}'.format(root, ext)
        if not delayed:
            if self.localize_gs and value.startswith('gs://'):
                self.backend.invoke("gsutil {} cp {} {}".format(
                    '-u {}'.format(get_default_gcp_project()) if self.get_requester_pays(value) else '',
                    value,
                    filepath
                ))
            elif os.path.isfile(path):
                transport.send(
                    value,
                    filepath
                )
        return filepath
